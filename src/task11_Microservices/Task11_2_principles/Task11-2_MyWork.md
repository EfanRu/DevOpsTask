# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Решение 1:

   Так как для нас актуален рынок РФ, который находится под санкциями, то мы будем рассматривать только отечественные решения, провайдеров, а так же решения с открытым исходным кодом.
   На рынке имеется только 1 провайдер предлагающий облачные решения https://gitflic.ru/ .
   Так как вариант 1, то выбор очевиден. Задание выполнено. Пара-па-Пам! ¯\_(ツ)_/¯

   Эх, жаль что такое решение вряд ли можно считать полноценным, так что пройдемся по критериям и оценим на сколько нам подходит Gitfflic.
   
+ облачная система;
+ система контроля версий Git;
+ репозиторий на каждый сервис;
+ запуск сборки по событию из системы контроля версий;
+ запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
+ несколько конфигураций для сборки из одного репозитория;
+ кастомные шаги при сборке;
+ собственные докер-образы для сборки проектов;
+ возможность развернуть агентов сборки на собственных серверах;
+ возможность параллельного запуска нескольких сборок;
+ возможность параллельного запуска тестов.
   
   Выводы:
   GitFlic в целом удовлетворяет большинству требований, но он не такой гибкий как иностранные решения и я не нашел у него никакого упоминания о хранилище секретных данных - это прям настораживает, но других вариантов все равно нет :(

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Решение 2:

   Splunk, Sumo Logic и ELK.
   Все серверы и пишут логи в stdout, котор

   OpenSearch как проект с открытым исходным кодом, берет свое начало у ElasticSearch (его fork). У ElasticSearch поменялся тип лицензии, который не совсем корректно использовать.
   Если честно, что-то там прям сложное со всеми лицензиями, а так как проекты выложены на github с открытым исходным кодом, то скорее всего в рамках РФ мы ими можем пользоваться и не париться.

   OpenSearch (ElasticSearch) нужен для анализа, хранения, поиска и работе с логами. Будет выступать центральным хранилищем данных.
   Kibana позволит визуализировать данные с помощью диаграмм и графиков в Elasticsearch.
   LogStash это сборщик логов, который не только собирает их, но и преобразует, а далее сохраняет в OpenSearch.
   В целом этот стек не единственный, но самый распространненый и по которому есть больше всего поддержки.


## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Решение 3: 

   Grafana + prometheus ну ведь самая популярная связка, которая удовлетворяет всем требованиям с огромной базой поддержки, плагинов и решенных вопросов.
   Так еще и оба open source!
   Думаю тут искать какие-то менее популярные решения смысла нет, а платных Российских продукты и сравнивать с grafana + prometheus не хочется.

   Графическая оболочка с разнообразными графиками и панелями + система оповещения нам обеспечивает Grafana.
   Метрики для Grafana мы забираем из Prometheus, как самое частое и удобное решение. В целои можно использовать любую БД, но зачем когда если готовая и проверенная временем связка.
   Данные в Prometheus будем собирать через http запросы с интересующих серверов.
   Экспорт же данных с серверов можно собирать через самый популярный, по количеству звёзд на gitHub, node_exporter или непосредственно из spring_boot приложений через Micrometer.

   

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
