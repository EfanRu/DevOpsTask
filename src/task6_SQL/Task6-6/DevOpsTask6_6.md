### Домашнее задание 6-6

# Задание 1
	Перед выполнением задания ознакомьтесь с документацией по администрированию MongoDB.
	Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD операция в MongoDB и её нужно прервать.
	Вы как инженер поддержки решили произвести данную операцию:

	    напишите список операций, которые вы будете производить для остановки запроса пользователя
	    предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB

# Решение 1
	Сначала нужно понимать масштаб проблемы из уст пользователя: что за запрос, сколько операций примерно нужно для его выполнения и что он делает.
	Далее если он отправил запрос на UPDATE, DELETE, INSERT без условия и в настоящее время стираются все данные в БД, то бежим находить Id операции по логину горе пользователя и применяем db.killOp(<opId>), а далее восстанавливаем БД. Если же запрос не критичный, но почему-то завис, то идем спокойно разбираемся, что к чему. Убить процесс всегда можно.
	Если у пользователя это постоянная проблема: запросы нужно отправлять, систему прямо сейчас не переделать и всё зависит от загрузки БД, то предлагаем пользователю использовать maxTimeMS(), которое ограничет время выполнения операции.
	
# Задание 2
	Перед выполнением задания познакомьтесь с документацией по Redis latency troobleshooting.
	Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. Причем отношение количества записанных key-value значений к количеству истёкших значений есть величина постоянная и увеличивается пропорционально количеству реплик сервиса.
	При масштабировании сервиса до N реплик вы увидели, что:

	    сначала рост отношения записанных значений к истекшим
	    Redis блокирует операции записи

	Как вы думаете, в чем может быть проблема?
	
# Решение 2
	Рост отношения записанных значений к истекшим после масштабирования сервиса логичен, так как после масштабирования увеличится поток записанных значений, а количество истекших не изменится. При прохождении времени TTL с момента масштабирования сервиса отношение записанных и истекщих должно выровняться.
	
	Если проблема актуальна сразу после масштабирования, то возможно поток с блокировкой попал на реплику, которая ещё не актуализировала информацию и заблокировала на это время поток.
	Ещё Redis блокирует операции записи в основном при выполнении операции BLPOP (или BRPOP), то есть ожидает поступления записи. Если timeout_callback не установлен, то в случае ошибки в потоке залокировавщим запись, она так и останется висеть зависшей. В этом случае нужно разблокировать запись RedisModule_AbortBlock.
	
	
# Здание 3
	Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей, в таблицах базы, пользователи начали жаловаться на ошибки вида:
```python
InterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '
```

	Как вы думаете, почему это начало происходить и как локализовать проблему?
	Какие пути решения данной проблемы вы можете предложить?
	
# Решение 3
	Локализовать данную проблему можно посмотрев на запросы, при которых появляется ошибка.
	Скорее всего проблема в том, что ответ от сервера получается слишком большой. По умолчанию max_allowed_packet = 1MB. Можно увеличить это значение или же просить пользователей делать менее ёмкие запросы, а то вдруг кто-то показал им что можно селектить без уловий, и они при каждом запросе грузят всю таблицу.
	
	
# Здание 4
	Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с 
	большим объемом данных лучше, чем MySQL.
	После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:

	`postmaster invoked oom-killer`

	Как вы думаете, что происходит?
	Как бы вы решили данную проблему?
	
# Решение 4
	Недостаточно оперативной памяти и oom-killer убивает самый жирный процесс, а это БД.
	Если есть бюджет, то добавил бы оперативной памяти, если она не сильно утекает.
	Если утекает сильно, а оперативки достаточно, но со временем она забивается, то тут нужно капать и искать проблемы.
	Если становится понятно, что оперативки не хватает при большом количестве подключений, так как каждое подключение из-за нашей специфики ГИС будет много весить, то логично ограничить количество потоков. Ещё вариант поискать как проапдейтить нашу БД и приложения, чтобы она работала эффективнее с большими по весу запросами. 
